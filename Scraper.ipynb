{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "source": [
    "Get Sitemap"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = 'https://openpsychometrics.org/tests/characters/stats/'\n",
    "sitemap_df = pd.read_html(ROOT)[0]\n",
    "sitemap_df=sitemap_df[2:-1]"
   ]
  },
  {
   "source": [
    "Get the labels of all the shows/works"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['A/', 'AD/', 'AHX/', 'AK/'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "work_pages = np.array(sitemap_df[sitemap_df.Name.str.match('[^\\d]')]['Name'])\n",
    "work_pages[:4]"
   ]
  },
  {
   "source": [
    "Get all of the trait code names, using Joffrey's page as a source"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [psychopath,empath, punchable,loveable, arrogant,humble, ðŸ˜ˆ,ðŸ˜‡, selfish,altruistic]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n    <tr>\n      <th>Trait</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>psychopath,empath</th>\n    </tr>\n    <tr>\n      <th>punchable,loveable</th>\n    </tr>\n    <tr>\n      <th>arrogant,humble</th>\n    </tr>\n    <tr>\n      <th>ðŸ˜ˆ,ðŸ˜‡</th>\n    </tr>\n    <tr>\n      <th>selfish,altruistic</th>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "joffrey = 'GOT/23/'\n",
    "URL = ROOT + joffrey\n",
    "mean_df = pd.read_html(URL)[0]\n",
    "mean_df['Trait'] = mean_df['Trait'].str.replace(' \\(', ',').str.replace('not ', '').str.replace('\\)', '')\n",
    "mean_df = pd.DataFrame(index=mean_df['Trait'])\n",
    "n_df = mean_df.copy()\n",
    "std_df = mean_df.copy()\n",
    "mean_df.head()"
   ]
  },
  {
   "source": [
    "Create URLs for all character pages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_urls = []\n",
    "for work in work_pages:\n",
    "    URL = ROOT + work\n",
    "    work_df = pd.read_html(URL)[0]\n",
    "    work_df = work_df[2:-1]\n",
    "    work_df['Name'] = work + work_df['Name']\n",
    "    character_urls.extend(list(work_df['Name']))\n",
    "# A few links point to image pages. Remove them\n",
    "character_urls = [char for char in character_urls if char[-4:] != '.jpg']"
   ]
  },
  {
   "source": [
    "Scrape all of the personality ratings, images, and character names and show names from each character's page"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "character_map = pd.DataFrame(columns=['Name', 'Show'])\n",
    "for char in character_urls:\n",
    "    mean_df[char] = None\n",
    "    std_df[char] = None\n",
    "    n_df[char] = None\n",
    "\n",
    "    URL = ROOT + char\n",
    "    response = requests.get(URL)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    description = soup.find('p').text\n",
    "    x = re.match(r\"(.+)is a character from (.+)\\. This page summarizes.+\", description)\n",
    "    character_map.loc[char] = x.group(1), x.group(2)\n",
    "    \n",
    "    img_url = soup.find('img').attrs.get('src')\n",
    "    if not os.path.isdir('images'):\n",
    "        os.makedirs('images')\n",
    "    response = requests.get(img_url)\n",
    "    filename = 'images/' + char.replace('/', '') + '.jpg'\n",
    "    with open(filename, 'wb') as out_file:\n",
    "        out_file.write(response.content)\n",
    "        out_file.close()\n",
    "\n",
    "    trait_df = pd.read_html(URL)[0]\n",
    "    trait_df['trait1'] = trait_df['Trait'].str.extract(r'(.+)\\s+?\\(')\n",
    "    trait_df['trait2'] = trait_df['Trait'].str.extract(r'.\\(not\\s+?(.+)\\)')\n",
    "    for index, row in trait_df.iterrows():\n",
    "        mean_df.loc[mean_df.index.str.match(re.escape(row['trait1'] + ',' + row['trait2'])),char] = 100 - row['Average rating']\n",
    "        n_df.loc[n_df.index.str.match(re.escape(row['trait1'] + ',' + row['trait2'])),char] = row['Number of raters']\n",
    "        std_df.loc[std_df.index.str.match(re.escape(row['trait1'] + ',' + row['trait2'])),char] = row['Rating standard deviation']\n",
    "\n",
    "        mean_df.loc[mean_df.index.str.match(re.escape(row['trait2'] + ',' + row['trait1'])),char] = row['Average rating']\n",
    "        n_df.loc[n_df.index.str.match(re.escape(row['trait2'] + ',' + row['trait1'])),char] = row['Number of raters']\n",
    "        std_df.loc[std_df.index.str.match(re.escape(row['trait2'] + ',' + row['trait1'])),char] = row['Rating standard deviation']"
   ]
  },
  {
   "source": [
    "Save results to CSVs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('data'):\n",
    "    os.makedirs('data')\n",
    "\n",
    "character_map.to_csv('data/character_map.csv')\n",
    "mean_df.to_csv('data/mean.csv')\n",
    "n_df.to_csv('data/n.csv')\n",
    "std_df.to_csv('data/std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}